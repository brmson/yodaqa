<?xml version="1.0" encoding="UTF-8" ?>
  <typeSystemDescription xmlns="http://uima.apache.org/resourceSpecifier">
    <name>CandidateAnswerTypes</name>
    <description>CandidateAnswerCAS type system</description>
    <vendor>yodaqa</vendor>
    <version>1.0</version>
    <types>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerInfo</name>
        <description>Meta-information on the generated candidate answer</description>
        <supertypeName>uima.cas.TOP</supertypeName>
        <features>
          <featureDescription>
            <name>canonText</name>
	    <description>Syntactically canonical form of the answer (without leading/trailing interpunction and the- and such)</description>
            <rangeTypeName>uima.cas.String</rangeTypeName>
          </featureDescription>
          <featureDescription>
            <name>features</name>
            <description>A set of features of this answer. Unmatched features should simply not be present, and order does not matter. Duplicates should NOT appear.</description>
            <rangeTypeName>uima.cas.FSArray</rangeTypeName>
            <elementType>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</elementType>
          </featureDescription>
          <featureDescription>
            <name>isLast</name>
            <description>Whether this is the last candidate answer CAS</description>
            <rangeTypeName>uima.cas.Boolean</rangeTypeName>
          </featureDescription>
        </features>
      </typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.PassageForParsing</name>
        <description>A passage on which a parser should be run</description>
        <supertypeName>uima.tcas.Annotation</supertypeName>
      </typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</name>
        <description>A feature matched on this answer. This type is for sub-classing to particular features.</description>
        <supertypeName>uima.cas.TOP</supertypeName>
        <features>
          <featureDescription>
            <name>value</name>
            <description>Feature value. Unmatched features are assumed 0. Ideally, the feature value should be in the interval of [0,1], but this is not enforced.</description>
            <rangeTypeName>uima.cas.Double</rangeTypeName>
          </featureDescription>
        </features>
      </typeDescription>
      <!-- N.B. for the time being, new types must be also added to a list in
           src/main/java/cz/brmlab/yodaqa/analysis/answer/AnswerFV.java -->
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_Occurences</name>
        <description>Answer Feature: Number of times this answer has been generated</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ResultLogScore</name>
        <description>Answer Feature: Log-score (by solr) of the result that produced the supporting passage</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PassageLogScore</name>
        <description>Answer Feature: Log-score of the passage that produced this answer</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsg</name>
        <description>Answer Feature: 1 if the origin of this answer is an in-document passage</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgFirst</name>
        <description>Answer Feature: 1 if the origin of this answer is the first passage of document (often a blurb packed with is-a relationships information)</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>

      <!-- XXX: This looks kind of really awful, ugh. But how to do this sensibly? -->
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</name>
        <description>Answer Feature: 1 if the origin of this answer is a passage that was selected because it matched a clue that's given in the feature name; "AbClue" means that the "about clue" was also in the title of the document (i.e. low signal).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueToken</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByCluePhrase</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueSV</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueNE</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueLAT</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueSubject</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueSubjectNE</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueSubjectToken</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueSubjectPhrase</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgByClueConcept</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginPsgByClue</supertypeName></typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgNP</name>
        <description>Answer Feature: 1 if the origin of this answer is a noun phrase parsed in a passage</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgNE</name>
        <description>Answer Feature: 1 if the origin of this answer is a named entity matched in a passage (TODO: also distinguish the type of matched named entity?)</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgNPByLATSubj</name>
	<description>Answer Feature: 1 if the origin of this answer is a noun phrase parsed in a passage that is object of a subject that matches question LAT ("What is critical mass of X?" -> "Critical mass is ***")</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginPsgSurprise</name>
	<description>Answer Feature: 1 if the origin of this answer is a passage that does not end with a question clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDocTitle</name>
        <description>Answer Feature: 1 if the origin of this answer is a document title</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRelation</name>
        <description>Answer Feature: 1 if the origin of this answer is a DBpedia property.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRNoClue</name>
        <description>Answer Feature: Negative evidence set to -1 if the origin of this answer is a DBpedia property that does not match any question clue in its label.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <!-- XXX: This looks kind of really awful, ugh. But how to do this sensibly? -->
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</name>
        <description>Answer Feature: 1 if the origin of this answer is a DBpedia property with a clue matching a word in the property name.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueToken</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRCluePhrase</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueSV</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueNE</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueLAT</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueSubject</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueSubjectNE</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueSubjectToken</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueSubjectPhrase</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginDBpRClueConcept</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_OriginDBpRClue</supertypeName></typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConcept</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConceptBySubject</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept subduing question subject clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConceptByLAT</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept subduing question focus clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginConceptByNE</name>
        <description>Answer Feature: 1 if the origin of this answer is a document corresponding to in-question concept subduing question NamedEntity clue</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_OriginMultiple</name>
        <description>Answer Feature: 1 if this answer was generated by multiple orthogonal annotators.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>

      <!-- XXX: This looks kind of really awful, ugh. But how to do this sensibly? -->
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</name>
        <description>Answer Feature: exp(-delta) where delta is number of characters between the clue and this answer in the passage text.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueToken</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistCluePhrase</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueSV</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueNE</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueLAT</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueSubject</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueSubjectNE</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueSubjectToken</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueSubjectPhrase</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>
      <typeDescription><name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_PsgDistClueConcept</name><supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature_PsgDistClue</supertypeName></typeDescription>

      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_NoTyCor</name>
        <description>Answer Feature: Negative evidence (-1.0), indicates a failed type coercion - i.e. both question and answer have some recognizable LATs but there is no match found</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATANone</name>
        <description>Answer Feature: Negative evidence (-1.0), indicates that no LAT has been generated for this answer at all</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SpWordNet</name>
        <description>Answer Feature: Specificity measured as WordNet graph exp(-distance), i.e. 1 is perfect match, 1/e is very specific, ..., 1/e^4 is already very non-specific</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATQNoWordNet</name>
        <description>Answer Feature: Question LAT has no derivable WordNet LATs.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATANoWordNet</name>
        <description>Answer Feature: Answer LAT has no derivable WordNet LATs (but does have *some* LATs).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorSpQHit</name>
        <description>Answer Feature: Question LAT is direct hypernyme of the answer LAT.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorSpAHit</name>
        <description>Answer Feature: Answer LAT is direct hypernyme of the question LAT.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorANE</name>
        <description>Answer Feature: Matched answer LAT has been generated by answer named entity type.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorADBp</name>
        <description>Answer Feature: Matched answer LAT has been generated by DBpedia rdf:type of the concept.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorADBpWN</name>
        <description>Answer Feature: Matched answer LAT has been generated by DBpedia dbpedia2:wordnet_type of the concept.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorAQuantity</name>
        <description>Answer Feature: Matched answer LAT has been generated by quantity statement.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorAQuantityCD</name>
        <description>Answer Feature: Matched answer LAT has been generated by numerical quantity statement.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorAWnInstance</name>
        <description>Answer Feature: Matched answer LAT has been generated by Wordnet instance-of relation to the concept in focus.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorADBpRelation</name>
        <description>Answer Feature: Matched answer LAT has been generated by a DBpedia property.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorPassageSp</name>
        <description>Answer Feature: Nearby match of a question LAT within the answer-bearing passage; this value carries the specificity of the question LAT, weighed by the word exp-inverse-distance from the answer (see below).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorPassageDist</name>
        <description>Answer Feature: Nearby match of a question LAT within the answer-bearing passage; this value carries exp-inverse-distance in characters between the LAT word and the answer segment, with 1 being that the LAT is one of the answer words or just nearby.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TyCorPassageInside</name>
        <description>Answer Feature: Nearby match of a question LAT within the answer-bearing passage; this value is 1.0 if the LAT word match is actually within the answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SimpleScore</name>
        <description>Answer Feature: A score as determined by our good old original simple scoring routine that uses just a handful of naive features.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATNE</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is the kind of named entity recognized.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATDBpType</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is based on DBpedia entity type.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATDBpWNType</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is based on DBpedia entity wordnet type.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATQuantity</name>
        <description>Answer Feature: Boolean value whether we generated a LAT based on seeing a quantity statement.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATQuantityCD</name>
        <description>Answer Feature: Boolean value whether we generated a LAT based on seeing a concrete numeric quantity.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATWnInstance</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is the other side of a Wordnet instance-of relation.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_LATDBpRelation</name>
        <description>Answer Feature: Boolean value whether we generated a LAT that is a DBpedia property name.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOMatchScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that are syntactically equivalent to this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOPrefixedScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that are syntactic prefixes of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOPrefixingScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that this answer is a syntactic prefix of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOSuffixedScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that are syntactic suffixes of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOSuffixingScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that this answer is a syntactic suffix of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOSubstredScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that are syntactic substrings of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOSubstringScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that this answer is a syntactic substring of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOMetaMatchScore</name>
        <description>Answer Feature (Clue Overlap): #of non-conceptual clues that either prefix or suffix this answer if both happens.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCMatchScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that are syntactically equivalent to this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCPrefixedScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that are syntactic prefixes of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCPrefixingScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that this answer is a syntactic prefix of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCSuffixedScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that are syntactic suffixes of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCSuffixingScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that this answer is a syntactic suffix of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCSubstredScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that are syntactic substrings of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCSubstringScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that this answer is a syntactic substring of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_ClOCMetaMatchScore</name>
        <description>Answer Feature (Clue Overlap): #of conceptual clues that either prefix or suffix this answer if both happens.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_EvDPrefixedScore</name>
        <description>Answer Feature (Evidence Diffusion): Sum of scores of all answers that are syntactic prefixes of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_EvDPrefixingScore</name>
        <description>Answer Feature (Evidence Diffusion): Sum of scores of all answers that this answer is a syntactic prefix of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_EvDSuffixedScore</name>
        <description>Answer Feature (Evidence Diffusion): Sum of scores of all answers that are syntactic suffixes of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_EvDSuffixingScore</name>
        <description>Answer Feature (Evidence Diffusion): Sum of scores of all answers that this answer is a syntactic suffix of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_EvDSubstredScore</name>
        <description>Answer Feature (Evidence Diffusion): Sum of scores of all answers that are syntactic substrings of this answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_EvDSubstringScore</name>
        <description>Answer Feature (Evidence Diffusion): Sum of scores of all answers that this answer is a syntactic substring of.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_TopAnswer</name>
        <description>Answer Feature: Boolean value whether we are one of the top answers selected by earlier scoring.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrHitsEv</name>
        <description>Answer Feature: Unbounded integer representing the number of search hits for question + answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrAHitsEv</name>
        <description>Answer Feature: Unbounded integer representing the number of search hits for answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrHitsANormEv</name>
        <description>Answer Feature: Unbounded integer representing the number of search hits for question + answer, normalized by number of search hits for just the answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrMaxScoreEv</name>
        <description>Answer Feature: Unbounded float representing the maximum score among search hits for question + answer.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_SolrHitsMaxScoreEv</name>
        <description>Answer Feature: Unbounded float representing SolrHitsEv * SolrMaxScoreEv.</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_Phase0Score</name>
        <description>Answer Feature: Confidence computed in phase 0 (for use by next phases).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
      <typeDescription>
        <name>cz.brmlab.yodaqa.model.CandidateAnswer.AF_Phase1Score</name>
        <description>Answer Feature: Confidence computed in phase 1 (for use by next phases).</description>
        <supertypeName>cz.brmlab.yodaqa.model.CandidateAnswer.AnswerFeature</supertypeName>
      </typeDescription>
    </types>
  </typeSystemDescription>
